{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports section\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim import corpora, models, similarities\n",
    "import string\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"text text text Valentyn hello\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'how', 'are', 'you', 'yeah']\n"
     ]
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # ADD MORE PROCESSING\n",
    "\n",
    "    corpus = text.split(' ')\n",
    "    return corpus\n",
    "\n",
    "print(tokenize(\"hello. how are you! yeah&\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 2 1 1 1 2 1 1 2 1 1 1 1 1 1]\n",
      "[[1.         0.09269042 0.        ]\n",
      " [0.09269042 1.         0.        ]\n",
      " [0.         0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "def tfidf_example(texts):\n",
    "    corpuses = [tokenize(text) for text in texts]\n",
    "\n",
    "    vocab = sorted(set(sum(corpuses, [])))\n",
    "    vocab_dict = {k:i for i,k in enumerate(vocab)}\n",
    "\n",
    "    X_tf = np.zeros((len(corpuses), len(vocab)), dtype=int)\n",
    "\n",
    "    for i, doc in enumerate(corpuses): # try with pandas\n",
    "        for word in doc:\n",
    "            X_tf[i, vocab_dict[word]] += 1\n",
    "\n",
    "    print(X_tf.astype(bool).sum(axis=0))\n",
    "    idf = np.log(X_tf.shape[0]/X_tf.astype(bool).sum(axis=0))\n",
    "    X_tfidf = X_tf * idf\n",
    "\n",
    "    X_tfidf_norm = X_tfidf / np.linalg.norm(X_tfidf, axis=1)[:,None]\n",
    "    M = X_tfidf_norm @ X_tfidf_norm.T # pytorch \n",
    "    print(M)\n",
    "\n",
    "    return \n",
    "\n",
    "texts = [\"text text text Valentyn hello\", \"hello hello\", \"Valentyn Nastya hello\", \"test qwerty\", \"test qwerty\"]\n",
    "texts_new = [\"Oleksandr likes to walk with his dog\", \"Oleksandr and his dog are best friends\", \"hello world this is dummy text\"]\n",
    "tfidf_example(texts_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. word2vec\n",
    "2. datasets parsing\n",
    "3. ml algorithms \n",
    "4. ml + fl \n",
    "5. pandas, pytorch \n",
    "6. entropy - where it marks wrong point\n",
    "7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6298e-01  3.0141e-01  5.7978e-01  6.6548e-02  4.5835e-01 -1.5329e-01\n",
      "  4.3258e-01 -8.9215e-01  5.7747e-01  3.6375e-01  5.6524e-01 -5.6281e-01\n",
      "  3.5659e-01 -3.6096e-01 -9.9662e-02  5.2753e-01  3.8839e-01  9.6185e-01\n",
      "  1.8841e-01  3.0741e-01 -8.7842e-01 -3.2442e-01  1.1202e+00  7.5126e-02\n",
      "  4.2661e-01 -6.0651e-01 -1.3893e-01  4.7862e-02 -4.5158e-01  9.3723e-02\n",
      "  1.7463e-01  1.0962e+00 -1.0044e+00  6.3889e-02  3.8002e-01  2.1109e-01\n",
      " -6.6247e-01 -4.0736e-01  8.9442e-01 -6.0974e-01 -1.8577e-01 -1.9913e-01\n",
      " -6.9226e-01 -3.1806e-01 -7.8565e-01  2.3831e-01  1.2992e-01  8.7721e-02\n",
      "  4.3205e-01 -2.2662e-01  3.1549e-01 -3.1748e-01 -2.4632e-03  1.6615e-01\n",
      "  4.2358e-01 -1.8087e+00 -3.6699e-01  2.3949e-01  2.5458e+00  3.6111e-01\n",
      "  3.9486e-02  4.8607e-01 -3.6974e-01  5.7282e-02 -4.9317e-01  2.2765e-01\n",
      "  7.9966e-01  2.1428e-01  6.9811e-01  1.1262e+00 -1.3526e-01  7.1972e-01\n",
      " -9.9605e-04 -2.6842e-01 -8.3038e-01  2.1780e-01  3.4355e-01  3.7731e-01\n",
      " -4.0251e-01  3.3124e-01  1.2576e+00 -2.7196e-01 -8.6093e-01  9.0053e-02\n",
      " -2.4876e+00  4.5200e-01  6.6945e-01 -5.4648e-01 -1.0324e-01 -1.6979e-01\n",
      "  5.9437e-01  1.1280e+00  7.5755e-01 -5.9160e-02  1.5152e-01 -2.8388e-01\n",
      "  4.9452e-01 -9.1703e-01  9.1289e-01 -3.0927e-01]\n"
     ]
    }
   ],
   "source": [
    "corpus = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "vector = corpus['computer']\n",
    "print(vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8323495 \n",
      "\n",
      "0.2676646 \n",
      "\n",
      "5.960464477539063e-08 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(corpus.similarity('woman', 'man'), '\\n')\n",
    "\n",
    "print(corpus.similarity('sandwich', 'man'), '\\n')\n",
    "print(corpus.distance(\"media\", \"media\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.711108\n",
      "[-0.215     0.87737  -0.063965 -0.042852  0.86186   0.89338  -0.35324\n",
      " -0.99678   0.15289   0.066144 -0.52534   0.68397   0.34208  -0.1562\n",
      " -0.73768   0.20957   0.16697  -0.039477 -0.43481  -0.24743   0.43591\n",
      " -0.058181  0.65537  -0.28042   0.37273   0.36553   0.1083   -0.67762\n",
      "  0.57978   0.38404   0.31276   1.0281    0.12181   0.47344   0.43453\n",
      " -0.5851    0.30595   0.43365  -1.0241   -0.72537  -1.7373   -0.65151\n",
      "  0.80613  -0.15615  -0.27365  -1.0545    0.52086   0.15272  -0.60403\n",
      " -0.33367  -0.17697  -0.2755   -0.42711   1.3151    0.37881  -1.2953\n",
      "  0.18912   0.41696   1.4792   -0.0141   -1.1892   -0.30676  -1.311\n",
      " -0.70105   0.67542   0.58331  -0.35846  -0.4816    0.31092  -0.065241\n",
      "  1.3389    0.16039  -0.88174  -0.57881   0.21681  -0.17917  -0.10835\n",
      "  0.25223  -0.9224   -0.28561   0.52446   0.40163   0.22797   0.68122\n",
      " -0.71693   1.2085    0.26086   0.30124   0.17424  -0.82416   0.96425\n",
      " -0.44436  -0.14183   0.84599  -0.59692  -0.42527   0.52494  -0.78475\n",
      "  0.31882   0.9449  ]\n"
     ]
    }
   ],
   "source": [
    "def tfidf_wordvec(texts):\n",
    "    model = Word2Vec(corpus, vector_size=len(texts), min_count=1)\n",
    "    return 0\n",
    "\n",
    "arr = [np.array(corpus['fascism']),\n",
    "       np.array(corpus['hitler']),\n",
    "       np.array(corpus['italy']),\n",
    "       np.array(corpus['mussolini'])]\n",
    "\n",
    "new_vector = arr[1] + arr[2]\n",
    "new_vector_normalized = new_vector / np.linalg.norm(new_vector)\n",
    "mussolini = arr[3] / np.linalg.norm(arr[3])\n",
    "cosine_sim = new_vector_normalized @ mussolini.T\n",
    "\n",
    "print(cosine_sim)\n",
    "\n",
    "print(corpus['democracy'])\n",
    "\n",
    "# print(corpus.similarity('woman', 'man'), '\\n')\n",
    "# print(corpus.similarity('fascism', 'mussolini'), '\\n')\n",
    "# print(corpus.similarity('fascism', 'trump'), '\\n')\n",
    "# print(corpus.distance(\"media\", \"media\"), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array( [corpus['democracy'], corpus['election'], corpus['public'], corpus['economy'], corpus['capitalism'], \n",
    "corpus['fascism'], corpus['eagle'], corpus['hitler'], corpus['mussolini'], corpus['freedom'], \n",
    "corpus['stalin'], corpus['gulag'], corpus['collectivism']])\n",
    "\n",
    "y_train = np.array([[0.1, 1.0, 0.9, 0.0], [0.2, 0.9, 0.8, 0.0], [0.8, 0.8, 0.5, 0.3], [0.1, 0.7, 0.9, 0.5], [0.1, 0.8, 0.9, 0.5],\n",
    "                    [0.2, 0.3, 0.4, 0.9], [0.1, 0.6, 0.2, 0.6], [0.1, 0.2, 0.1, 0.9], [0.1, 0.2, 0.1, 0.9], [0.1, 0.9, 0.9, 0.1], \n",
    "                    [0.9, 0.2, 0.1, 0.1], [0.9, 0.1, 0.1, 0.1], [0.9, 0.3, 0.3, 0.6]])\n",
    "\n",
    "def add_property(x, y, property, vector):\n",
    "    x = np.append(x, [corpus[property]], axis=0)\n",
    "    y = np.append(y, [vector], axis=0)\n",
    "    return x, y\n",
    "\n",
    "x_train, y_train = add_property(x_train, y_train, 'culture', [0.8, 0.8, 0.5, 0.1])\n",
    "x_train, y_train = add_property(x_train, y_train, 'society', [0.8, 0.8, 0.4, 0.1])\n",
    "x_train, y_train = add_property(x_train, y_train, 'trump', [0.1, 0.2, 0.6, 0.6])\n",
    "x_train, y_train = add_property(x_train, y_train, 'biden', [0.1, 0.7, 0.4, 0.4])\n",
    "x_train, y_train = add_property(x_train, y_train, 'obama', [0.1, 0.7, 0.4, 0.2])\n",
    "x_train, y_train = add_property(x_train, y_train, 'clinton', [0.1, 0.7, 0.4, 0.4])\n",
    "x_train, y_train = add_property(x_train, y_train, 'satana', [0.9, 0.9, 0.9, 0.9])\n",
    "x_train, y_train = add_property(x_train, y_train, 'jesus', [0.9, 0.9, 0.9, 0.1])\n",
    "x_train, y_train = add_property(x_train, y_train, 'dictatorship', [0.9, 0.1, 0.1, 0.9])\n",
    "x_train, y_train = add_property(x_train, y_train, 'socialism', [0.9, 0.1, 0.1, 0.3])\n",
    "\n",
    "# x_train, y_train = add_property(x_train, y_train, 'party', [0.9, 0.5, 0.4, 0.4])\n",
    "# x_train, y_train = add_property(x_train, y_train, 'party', [0.9, 0.5, 0.4, 0.4])\n",
    "# x_train, y_train = add_property(x_train, y_train, 'party', [0.9, 0.5, 0.4, 0.4])\n",
    "# x_train, y_train = add_property(x_train, y_train, 'party', [0.9, 0.5, 0.4, 0.4])\n",
    "# x_train, y_train = add_property(x_train, y_train, 'party', [0.9, 0.5, 0.4, 0.4])\n",
    "# x_train, y_train = add_property(x_train, y_train, 'party', [0.9, 0.5, 0.4, 0.4])\n",
    "# x_train, y_train = add_property(x_train, y_train, 'party', [0.9, 0.5, 0.4, 0.4])\n",
    "# x_train, y_train = add_property(x_train, y_train, 'party', [0.9, 0.5, 0.4, 0.4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.56809288 0.75469388 0.71935965 0.51559354]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the degree of the polynomial features\n",
    "degree = 3  # You can experiment with different degrees\n",
    "\n",
    "# Create a pipeline that includes PolynomialFeatures and LinearRegression\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=degree)),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict([corpus[\"labour\"]])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.582 0.451 0.316 0.515]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "# Create a RandomForestRegressor wrapped in MultiOutputRegressor for multi-dimensional output\n",
    "model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict([corpus[\"lenin\"]])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.65840325 0.43756947 0.37288896 0.29836469]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVR, wrapped in MultiOutputRegressor\n",
    "model = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1.0, epsilon=0.1)))\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict([corpus[\"lenin\"]])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiply_vectors(x, y):\n",
    "    return 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
