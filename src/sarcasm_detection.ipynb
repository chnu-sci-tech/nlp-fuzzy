{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ideas:\n",
    "- автоматичне виявлення сарказму в соц мережах (твіттер etc)\n",
    "- генерація саркастичних висловлювань \n",
    "- аналіз впливу емодзі пунктуація \n",
    "- сарказм у різних культурах порівняння \n",
    "- в політичних текстах\n",
    "- в мультимодальному контексті (текст зображення голос)\n",
    "- у новинах та заголовках\n",
    "- \n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports section\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim import corpora, models, similarities\n",
    "import string\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign mood scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {\n",
    "    \"anxious\": 0.1,\n",
    "    \"furious\": 0.0,\n",
    "    \"peaceful\": 0.9, \n",
    "    \"hate\": 0.0,\n",
    "    \"joyful\": 0.9, \n",
    "    \"unacceptable\": 0.1,\n",
    "    \"thrilled\": 0.9, \n",
    "    \"infuriating\": 0.1,\n",
    "    \"irate\": 0.1, \n",
    "    \"terrible\": 0.1,\n",
    "    \"nervous\": 0.2,\n",
    "    \"melancholy\": 0.3, \n",
    "    \"depressed\": 0.1, \n",
    "    \"gloomy\": 0.1, \n",
    "    \"serene\": 0.8, \n",
    "    \"elated\": 0.8,\n",
    "    \"ecstatic\": 0.9,\n",
    "    \"overjoyed\": 0.9,\n",
    "    \"gleeful\": 0.7,\n",
    "    \"cheerful\": 0.7,\n",
    "    \"optimistic\": 0.7,\n",
    "    \"buoyant\": 0.6,\n",
    "    \"enthusiastic\": 0.7,\n",
    "    \"upbeat\": 0.6,\n",
    "    \"festive\": 0.6,\n",
    "    \"playful\": 0.6,\n",
    "    \"vivacious\": 0.6,\n",
    "    \"amused\": 0.7,\n",
    "    \"blissful\": 0.6,\n",
    "    \"grateful\": 0.8,\n",
    "    \"tranquil\": 0.8,\n",
    "    \"relaxed\": 0.7,\n",
    "    \"comfortable\": 0.6,\n",
    "    \"cozy\": 0.6,\n",
    "    \"warm\": 0.6,\n",
    "    \"inviting\": 0.6, \n",
    "    \"satisfied\": 0.5,\n",
    "    \"pleasant\": 0.6, \n",
    "    \"pleased\" : 0.7, \n",
    "    \"happy\": 0.8\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read adjectives from txt file and define array of given adjactive scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.6298e-01  3.0141e-01  5.7978e-01  6.6548e-02  4.5835e-01 -1.5329e-01\n",
      "  4.3258e-01 -8.9215e-01  5.7747e-01  3.6375e-01  5.6524e-01 -5.6281e-01\n",
      "  3.5659e-01 -3.6096e-01 -9.9662e-02  5.2753e-01  3.8839e-01  9.6185e-01\n",
      "  1.8841e-01  3.0741e-01 -8.7842e-01 -3.2442e-01  1.1202e+00  7.5126e-02\n",
      "  4.2661e-01 -6.0651e-01 -1.3893e-01  4.7862e-02 -4.5158e-01  9.3723e-02\n",
      "  1.7463e-01  1.0962e+00 -1.0044e+00  6.3889e-02  3.8002e-01  2.1109e-01\n",
      " -6.6247e-01 -4.0736e-01  8.9442e-01 -6.0974e-01 -1.8577e-01 -1.9913e-01\n",
      " -6.9226e-01 -3.1806e-01 -7.8565e-01  2.3831e-01  1.2992e-01  8.7721e-02\n",
      "  4.3205e-01 -2.2662e-01  3.1549e-01 -3.1748e-01 -2.4632e-03  1.6615e-01\n",
      "  4.2358e-01 -1.8087e+00 -3.6699e-01  2.3949e-01  2.5458e+00  3.6111e-01\n",
      "  3.9486e-02  4.8607e-01 -3.6974e-01  5.7282e-02 -4.9317e-01  2.2765e-01\n",
      "  7.9966e-01  2.1428e-01  6.9811e-01  1.1262e+00 -1.3526e-01  7.1972e-01\n",
      " -9.9605e-04 -2.6842e-01 -8.3038e-01  2.1780e-01  3.4355e-01  3.7731e-01\n",
      " -4.0251e-01  3.3124e-01  1.2576e+00 -2.7196e-01 -8.6093e-01  9.0053e-02\n",
      " -2.4876e+00  4.5200e-01  6.6945e-01 -5.4648e-01 -1.0324e-01 -1.6979e-01\n",
      "  5.9437e-01  1.1280e+00  7.5755e-01 -5.9160e-02  1.5152e-01 -2.8388e-01\n",
      "  4.9452e-01 -9.1703e-01  9.1289e-01 -3.0927e-01]\n"
     ]
    }
   ],
   "source": [
    "corpus = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "vector = corpus['computer']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''\n",
    "\n",
    "# with open('../sets/adjectives.txt', 'r') as file:\n",
    "#     data = file.read().replace('\\n', '')\n",
    "\n",
    "# adjectives = data.split(',')\n",
    "\n",
    "with open('../sets/english-adjectives.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', ',')\n",
    "\n",
    "adjectives = data.split(',')\n",
    "\n",
    "\n",
    "adjectives_scored = {}\n",
    "\n",
    "# indx = corpus.index()\n",
    "\n",
    "for adjective in adjectives:\n",
    "    if adjective in corpus:\n",
    "        adjectives_scored[adjective] = corpus[adjective]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extrapolate mood scores to adjactives using ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "lexicon_trained = {}\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVR, wrapped in MultiOutputRegressor\n",
    "model = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1.0)))\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for key in lexicon.keys():\n",
    "    x_train.append(adjectives_scored[key])\n",
    "    y_train.append([lexicon[key], 0])\n",
    "\n",
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "    # Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "for key in adjectives_scored:\n",
    "    result = model.predict([adjectives_scored[key]])\n",
    "    lexicon_trained[key] = result[0][0]\n",
    "\n",
    "print(lexicon_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic NLP techniques to extract mood score changes for text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "def calculate_mood_series(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # Tokenize text into words\n",
    "    words = word_tokenize(text)\n",
    "    # Apply lemmatization\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    mood_series = []\n",
    "    for word in lemmatized_words:\n",
    "        if word in lexicon_trained.keys():\n",
    "            mood_series.append(lexicon_trained[word])\n",
    "    return mood_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45973176454385156, 0.3325276673498717, 0.42756880944163317]\n"
     ]
    }
   ],
   "source": [
    "example_text = \"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of light, it was the season of darkness, it was the spring of hope, it was the winter of despair.\"\n",
    "\n",
    "print(calculate_mood_series(example_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "may be try classification instead of regression?\n",
    "classify in positive and negative moods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon = {\n",
    "    \"anxious\": False,\n",
    "    \"furious\": False,\n",
    "    \"peaceful\": True, \n",
    "    \"hate\": False,\n",
    "    \"joyful\": 0.9, \n",
    "    \"unacceptable\": 0.1,\n",
    "    \"thrilled\": 0.9, \n",
    "    \"infuriating\": 0.1,\n",
    "    \"irate\": 0.1, \n",
    "    \"terrible\": 0.1,\n",
    "    \"nervous\": 0.2,\n",
    "    \"melancholy\": 0.3, \n",
    "    \"depressed\": 0.1, \n",
    "    \"gloomy\": 0.1, \n",
    "    \"serene\": 0.8, \n",
    "    \"elated\": 0.8,\n",
    "    \"ecstatic\": 0.9,\n",
    "    \"overjoyed\": 0.9,\n",
    "    \"gleeful\": 0.7,\n",
    "    \"cheerful\": 0.7,\n",
    "    \"optimistic\": 0.7,\n",
    "    \"buoyant\": 0.6,\n",
    "    \"enthusiastic\": 0.7,\n",
    "    \"upbeat\": 0.6,\n",
    "    \"festive\": 0.6,\n",
    "    \"playful\": 0.6,\n",
    "    \"vivacious\": 0.6,\n",
    "    \"amused\": 0.7,\n",
    "    \"blissful\": 0.6,\n",
    "    \"grateful\": 0.8,\n",
    "    \"tranquil\": 0.8,\n",
    "    \"relaxed\": 0.7,\n",
    "    \"comfortable\": 0.6,\n",
    "    \"cozy\": 0.6,\n",
    "    \"warm\": 0.6,\n",
    "    \"inviting\": 0.6, \n",
    "    \"satisfied\": 0.5,\n",
    "    \"pleasant\": 0.6, \n",
    "    \"pleased\" : 0.7, \n",
    "    \"happy\": 0.8\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse timeseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try emojis/punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['😄', '👋', '✨', '🌈', '🌍', '🌞', '🚀', '🎉', '☕']\n",
      "[':grinning_face_with_smiling_eyes:', ':waving_hand:', ':sparkles:', ':rainbow:', ':globe_showing_Europe-Africa:', ':sun_with_face:', ':rocket:', ':party_popper:', ':hot_beverage:']\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "# def extract_emojis(s):\n",
    "#   return ''.join(c for c in s if c in emoji.distinct_emoji_list('en'))\n",
    "\n",
    "example_text = \"Hey there! 👋 How's your day going? 🌞 Whether you're sipping coffee ☕, exploring new places 🌍, or just chilling at home �, I hope it's amazing! 🎉 Don't forget to smile 😄 and spread positivity! ✨ Life's a journey 🚀, so enjoy every moment! 🌈✨\"\n",
    "emoji_list = emoji.distinct_emoji_list(example_text)\n",
    "print(emoji_list)\n",
    "\n",
    "unicode_values = [emoji.demojize(e).encode('unicode_escape').decode('utf-8') for e in emoji_list]\n",
    "print(unicode_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use two markers at the same time: text mood classifications (positive negative -> function) and emoji+punctuation "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
