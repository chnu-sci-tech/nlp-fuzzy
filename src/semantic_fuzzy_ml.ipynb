{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's try approach semantic analysis with fuzzy logic + ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports section\n",
    "import numpy as np\n",
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from gensim import corpora, models, similarities\n",
    "import string\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = {}\n",
    "expected['lonely'] = [0.1, 0.5, 1, 0.6, 0.1, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the lexicon with mood vectors\n",
    "moods = {0: \"Angry\", 1: \"Worried\", 2: \"Sad\", 3: \"Calm\", 4: \"Happy\", 5: \"Excited\"}\n",
    "moods_indeces = {y.lower(): x for x, y in moods.items()}\n",
    "\n",
    "lexicon = {\n",
    "    # \"frustrated\": [0.8, 0.4, 0.3, 0, 0, 0], \n",
    "    \"anxious\": [0.3, 0.9, 0.4, 0, 0, 0.1],\n",
    "    # \"disappointed\": [0.5, 0.3, 0.8, 0.1, 0, 0], \n",
    "    \"furious\": [0.9, 0.3, 0.2, 0, 0, 0],\n",
    "    \"peaceful\": [0, 0, 0, 1, 0.4, 0.2], \n",
    "    \"hate\": [0.9, 0.3, 0.3, 0, 0, 0],\n",
    "    \"joyful\": [0, 0, 0, 0.2, 0.9, 0.7], \n",
    "    \"unacceptable\": [0.9, 0.6, 0.6, 0, 0, 0],\n",
    "    \"thrilled\": [0, 0, 0, 0, 0.6, 1], \n",
    "    \"infuriating\": [0.9, 0.8, 0.6, 0, 0, 0],\n",
    "    \"irate\": [0.9, 0.2, 0.1, 0, 0, 0], \n",
    "    \"terrible\": [0.9, 0.7, 0.7, 0, 0, 0],\n",
    "    \"nervous\": [0.2, 0.8, 0.3, 0.1, 0, 0.2],\n",
    "    \"melancholy\": [0.1, 0.4, 0.9, 0.2, 0, 0], \n",
    "    \"depressed\": [0.1, 0.1, 0.9, 0.2, 0, 0], \n",
    "    \"gloomy\": [0.1, 0.1, 0.8, 0.3, 0, 0], \n",
    "    \"serene\": [0, 0, 0, 0.9, 0.8, 0.9], \n",
    "    \"elated\": [0, 0, 0, 0.1, 0.8, 0.9],\n",
    "    \"ecstatic\": [0, 0, 0, 0, 0.7, 1],\n",
    "    \"overjoyed\": [0.1, 0.1, 0.1, 0.1, 1, 0.9],\n",
    "    \"gleeful\": [0.1, 0.1, 0.1, 0.1, 0.9, 0.8],\n",
    "    \"cheerful\": [0.1, 0.1, 0.1, 0.1, 0.8, 0.5],\n",
    "    \"optimistic\": [0.1, 0.2, 0.1, 0.7, 0.8, 0.6],\n",
    "    \"buoyant\": [0.1, 0.2, 0.1, 0.8, 0.7, 0.7],\n",
    "    \"enthusiastic\": [0.2, 0.3, 0.1, 0.6, 0.8, 0.9],\n",
    "    \"upbeat\": [0.1, 0.2, 0.1, 0.7, 0.8, 0.7],\n",
    "    \"festive\": [0.1, 0.1, 0.1, 0.7, 0.8, 0.7],\n",
    "    \"playful\": [0.1, 0.2, 0.1, 0.6, 0.7, 0.8],\n",
    "    \"vivacious\": [0.1, 0.2, 0.1, 0.6, 0.8, 0.7],\n",
    "    \"jovial\": [0.1, 0.2, 0.1, 0.7, 0.8, 0.7],\n",
    "    \"amused\": [0.1, 0.2, 0.1, 0.6, 0.7, 0.7],\n",
    "    \"blissful\": [0.1, 0.1, 0.1, 0.8, 0.9, 0.7],\n",
    "    \"grateful\": [0.1, 0.1, 0.1, 0.8, 0.9, 0.7],\n",
    "    \"tranquil\": [0.1, 0.1, 0.1, 0.9, 0.8, 0.6],\n",
    "    \"relaxed\": [0.1, 0.1, 0.1, 0.9, 0.8, 0.6],\n",
    "    \"comfortable\": [0.1, 0.1, 0.1, 0.8, 0.8, 0.6],\n",
    "    \"cozy\": [0.1, 0.1, 0.1, 0.8, 0.8, 0.6],\n",
    "    \"warm\": [0.1, 0.1, 0.1, 0.8, 0.8, 0.6],\n",
    "    \"inviting\": [0.1, 0.1, 0.1, 0.8, 0.8, 0.6], \n",
    "    \"satisfied\": [0.1, 0.1, 0.2, 0.6, 0.5, 0.3],\n",
    "    \"pleasant\": [0.1, 0.1, 0.1, 0.8, 0.8, 0.6], \n",
    "    \"pleased\" : [0.1, 0.1, 0.1, 0.9, 0.8, 0.3], \n",
    "    \"mellow\": [0.1, 0.1, 0.1, 0.8, 0.8, 0.6] , \n",
    "    \"happy\": [0.1, 0.1, 0.1, 0.7, 1, 0.6]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = api.load('glove-wiki-gigaword-100')\n",
    "\n",
    "vector = corpus['computer']\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ''\n",
    "\n",
    "with open('../sets/adjectives.txt', 'r') as file:\n",
    "    data = file.read().replace('\\n', '')\n",
    "\n",
    "adjectives = data.split(',')\n",
    "print(adjectives[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjectives_vectors = {}\n",
    "\n",
    "for adjective in adjectives:\n",
    "    adjectives_vectors[adjective] = corpus[adjective]\n",
    "\n",
    "print(adjectives_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ML we can extend defined vectors to the whole space of words of interest.\n",
    "ML - classification and regression;\n",
    "Here we are going to apply some regression:\n",
    "- Polynomial regression\n",
    "- Support vector regression \n",
    "- Decision tree regression\n",
    "- Random forest regression \n",
    "- \n",
    "\n",
    "Also we ca apply:\n",
    "- Dimensionality reduction \n",
    "- Kohonen map\n",
    "- \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lexicon[\"frustrated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Define the degree of the polynomial features\n",
    "degree = 3  # You can experiment with different degrees\n",
    "\n",
    "# Create a pipeline that includes PolynomialFeatures and LinearRegression\n",
    "model = Pipeline([\n",
    "    ('poly', PolynomialFeatures(degree=degree)),\n",
    "    ('linear', LinearRegression())\n",
    "])\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for key in lexicon.keys():\n",
    "    x_train.append(adjectives_vectors[key])\n",
    "    y_train.append(lexicon[key])\n",
    "\n",
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "lexicon_trained = {}\n",
    "for key in adjectives_vectors:\n",
    "    result = model.predict([adjectives_vectors[key]])\n",
    "    lexicon_trained[key] = result\n",
    "\n",
    "print(lexicon_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moods = {0: \"Angry\", 1: \"Worried\", 2: \"Sad\", 3: \"Calm\", 4: \"Happy\", 5: \"Excited\"}\n",
    "\n",
    "\n",
    "print(lexicon_trained['obnoxious'])\n",
    "print(lexicon_trained['lonely'])\n",
    "print(lexicon_trained['hilarious'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVR, wrapped in MultiOutputRegressor\n",
    "model = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1.0)))\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for key in lexicon.keys():\n",
    "    x_train.append(adjectives_vectors[key])\n",
    "    y_train.append(lexicon[key])\n",
    "\n",
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "lexicon_trained = {}\n",
    "for key in adjectives_vectors:\n",
    "    result = model.predict([adjectives_vectors[key]])\n",
    "    lexicon_trained[key] = result\n",
    "\n",
    "print(lexicon_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moods = {0: \"Angry\", 1: \"Worried\", 2: \"Sad\", 3: \"Calm\", 4: \"Happy\", 5: \"Excited\"}\n",
    "\n",
    "print(lexicon_trained['obnoxious'])\n",
    "print(lexicon_trained['lonely'])\n",
    "print(lexicon_trained['hilarious'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a pipeline with StandardScaler and SVR, wrapped in MultiOutputRegressor\n",
    "model = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1.0)))\n",
    "\n",
    "x_train, y_train = [], []\n",
    "for key in lexicon.keys():\n",
    "    x_train.append(adjectives_vectors[key])\n",
    "    y_train.append([lexicon[key][0], 0])\n",
    "\n",
    "x_train_np = np.array(x_train)\n",
    "y_train_np = np.array(y_train)\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "lexicon_trained = {}\n",
    "for key in adjectives_vectors:\n",
    "    result = model.predict([adjectives_vectors[key]])\n",
    "    lexicon_trained[key] = result[0][0]\n",
    "\n",
    "print(lexicon_trained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moods = {0: \"Angry\", 1: \"Worried\", 2: \"Sad\", 3: \"Calm\", 4: \"Happy\", 5: \"Excited\"}\n",
    "\n",
    "print(lexicon_trained['obnoxious'])\n",
    "print(lexicon_trained['lonely'])\n",
    "print(lexicon_trained['hilarious'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_trained = {}\n",
    "for key in adjectives_vectors:\n",
    "    lexicon_trained[key] = [0, 0, 0, 0, 0, 0]\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "for i in range(6):\n",
    "    # Create a pipeline with StandardScaler and SVR, wrapped in MultiOutputRegressor\n",
    "    model = MultiOutputRegressor(make_pipeline(StandardScaler(), SVR(kernel='rbf', C=1.0)))\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    for key in lexicon.keys():\n",
    "        x_train.append(adjectives_vectors[key])\n",
    "        y_train.append([lexicon[key][i], 0])\n",
    "\n",
    "    x_train_np = np.array(x_train)\n",
    "    y_train_np = np.array(y_train)\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    for key in adjectives_vectors:\n",
    "        result = model.predict([adjectives_vectors[key]])\n",
    "        lexicon_trained[key][i] = result[0][0]\n",
    "\n",
    "print(lexicon_trained)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moods = {0: \"Angry\", 1: \"Worried\", 2: \"Sad\", 3: \"Calm\", 4: \"Happy\", 5: \"Excited\"}\n",
    "\n",
    "print(lexicon_trained['obnoxious'])\n",
    "print(lexicon_trained['lonely'])\n",
    "print(lexicon_trained['hilarious'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
